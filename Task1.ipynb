{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification Task \n",
    "\n",
    "## What we need\n",
    "\n",
    "We need a function called check_msm_identification that it easy to use and performs the identification check described in [this paper](https://arxiv.org/pdf/1907.13093.pdf). The different variants (e.g. different methods of sampling uniformly from likelihood level sets) can be selected via the optional arguments of check_ml_identification.  The output will either be a dictionary (if it is a small set of outputs that every user will want) or a results object similar to the result of estimate_ml (if there are many different test statistics).\n",
    "\n",
    "## Task 1: Planning\n",
    "\n",
    "- Write down which model specific inputs a user has to supply in order to do an identification check. The names should be aligned with estimate_ml where possible. It will definitely be a likelihood function and a result of estimate_msm but there might be more. \n",
    "- Write down which kinds of outputs a user will get, what they mean and how they should be visualized in a paper (plots, tables, ...). \n",
    "- Write docstrings for check_ml_identification before you actually implement it\n",
    "- Adjust our [simple example](https://estimagic.readthedocs.io/en/stable/getting_started/estimation/first_msm_estimation_with_estimagic.html) such that it has a second variable that can be arbitrarily correlated with x (i.e. add an identification problem)\n",
    "- Start to write a tutorial in a notebook that shows how the new function will be used and what the outputs mean\n",
    "\n",
    "## Remarks\n",
    "\n",
    "- You can for now assume that the model parameters (params) are a 1d numpy array. We talk about making this more flexible later. \n",
    "- The idea behind writing the documentation first is that it lets you focus completely on a user friendly interface and a high level understanding. Also, we will probably ask for changes after you show us your proposed interface. If you had already implemented it, you would have to change it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimate_msm\n",
    "https://estimagic.readthedocs.io/en/stable/reference_guides/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>p_value</th>\n",
       "      <th>free</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>0.453680</td>\n",
       "      <td>2.365182e+10</td>\n",
       "      <td>-4.635671e+10</td>\n",
       "      <td>4.635671e+10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope1</th>\n",
       "      <td>-0.979460</td>\n",
       "      <td>1.273175e+02</td>\n",
       "      <td>-2.505172e+02</td>\n",
       "      <td>2.485583e+02</td>\n",
       "      <td>0.993862</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope2</th>\n",
       "      <td>0.453677</td>\n",
       "      <td>2.583621e+10</td>\n",
       "      <td>-5.063804e+10</td>\n",
       "      <td>5.063804e+10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>0.988449</td>\n",
       "      <td>5.628280e+02</td>\n",
       "      <td>-1.102134e+03</td>\n",
       "      <td>1.104111e+03</td>\n",
       "      <td>0.998599</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              value  standard_error      ci_lower      ci_upper   p_value  \\\n",
       "intercept  0.453680    2.365182e+10 -4.635671e+10  4.635671e+10  1.000000   \n",
       "slope1    -0.979460    1.273175e+02 -2.505172e+02  2.485583e+02  0.993862   \n",
       "slope2     0.453677    2.583621e+10 -5.063804e+10  5.063804e+10  1.000000   \n",
       "sd         0.988449    5.628280e+02 -1.102134e+03  1.104111e+03  0.998599   \n",
       "\n",
       "           free stars  \n",
       "intercept  True        \n",
       "slope1     True        \n",
       "slope2     True        \n",
       "sd         True        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CALCULATE NECESSARY INPUTS (as in identification_check_with_estimagic.ipynb)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import estimagic as em\n",
    "\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "def simulate_data(params, n_draws, rng,correlation=0.7):\n",
    "\n",
    "    mu = np.array([0.0, 0.0])\n",
    "    var_cov = np.array([\n",
    "            [  1, correlation],\n",
    "            [ correlation,  1],\n",
    "        ])\n",
    "    x = rng.multivariate_normal(mu, var_cov, size=n_draws)\n",
    "    x1 = x[:,0]\n",
    "    x2 = x[:,1]\n",
    "    e = rng.normal(0, params.loc[\"sd\", \"value\"], size=n_draws)\n",
    "    y = params.loc[\"intercept\", \"value\"] + params.loc[\"slope1\", \"value\"] * x1 + params.loc[\"slope2\", \"value\"] + e\n",
    "    return pd.DataFrame({\"y\": y, \"x1\": x1, \"x2\": x2})\n",
    "\n",
    "true_params = pd.DataFrame(\n",
    "    data=[[2, -np.inf], [-1, -np.inf], [-1, -np.inf], [1, 1e-10]],\n",
    "    columns=[\"value\", \"lower_bound\"],\n",
    "    index=[\"intercept\", \"slope1\", \"slope2\", \"sd\"],\n",
    ")\n",
    "\n",
    "true_params = pd.DataFrame(\n",
    "    data=[[2, -np.inf], [-1, -np.inf], [-1, -np.inf], [1, 1e-10]],\n",
    "    columns=[\"value\", \"lower_bound\"],\n",
    "    index=[\"intercept\", \"slope1\", \"slope2\", \"sd\"],\n",
    ")\n",
    "\n",
    "data = simulate_data(true_params, n_draws=1000, rng=rng)\n",
    "\n",
    "def calculate_moments(sample):\n",
    "    moments = {\n",
    "        \"y_mean\": sample[\"y\"].mean(),\n",
    "        \"x1_mean\": sample[\"x1\"].mean(),\n",
    "        \"x2_mean\": sample[\"x2\"].mean(),\n",
    "        \"yx1_mean\": (sample[\"y\"] * sample[\"x1\"]).mean(),\n",
    "        \"yx2_mean\": (sample[\"y\"] * sample[\"x2\"]).mean(),\n",
    "        \"y_sqrd_mean\": (sample[\"y\"] ** 2).mean(),\n",
    "        \"x1_sqrd_mean\": (sample[\"x1\"] ** 2).mean(),\n",
    "        \"x2_sqrd_mean\": (sample[\"x1\"] ** 2).mean(),\n",
    "    }\n",
    "    return pd.Series(moments)\n",
    "\n",
    "empirical_moments = calculate_moments(data)\n",
    "\n",
    "\n",
    "def simulate_moments(params, n_draws=10_000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    sim_data = simulate_data(params, n_draws, rng)\n",
    "    sim_moments = calculate_moments(sim_data)\n",
    "\n",
    "    return sim_moments\n",
    "\n",
    "\n",
    "moments_cov = em.get_moments_cov(\n",
    "    data, calculate_moments, bootstrap_kwargs={\"n_draws\": 5_000, \"seed\": 0}\n",
    ")\n",
    "\n",
    "start_params = true_params.assign(value=[100, 100, 100, 100])\n",
    "\n",
    "res = em.estimate_msm(\n",
    "    simulate_moments,\n",
    "    empirical_moments,\n",
    "    moments_cov,\n",
    "    start_params,\n",
    "    optimize_options={\"algorithm\":\"scipy_lbfgsb\"},\n",
    ")\n",
    "\n",
    "res.summary() # !check that standard_error is without NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_excel(\"test_data.xlsx\")\n",
    "#moments_cov.to_excel(\"test_moments_cov.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.i Draws on the level set\n",
    "## Sampling for step 2.i)\n",
    "#### 1. Direct approach\n",
    " - draw values from the space - either randomly or pseudo-randomly (Sobol or Halton)\n",
    " - assign weights proportionally to the bandwidth criterion (indicator function)\n",
    " - drawback - effective sample size can be samll relative to the parameter space; especially when the dimention of \\theta is moderately large\n",
    "\n",
    "#### 2. Adaptive Sampling by Population Monte Carlo\n",
    "- constructing a sequence of proposal distributions with higher acceptance rate\n",
    "- to do later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats.qmc as qmc\n",
    "import cvxpy as cp\n",
    "\n",
    "from estimagic.estimation.msm_weighting import get_weighting_matrix\n",
    "from estimagic.estimation.estimate_msm import get_msm_optimization_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from identification_check import check_msm_identification\n",
    "from identification_check import sampling_level_sets\n",
    "from identification_check import calculate_quasi_jacobian\n",
    "from identification_check import category_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data.shape[0]\n",
    "bandwidth = math.sqrt(2 * math.log(math.log(n)) / n)\n",
    "sampling= \"sobol\"\n",
    "grid_sub,moms_sub = sampling_level_sets(simulate_moments,res,moments_cov,10000,bandwidth,'diagonal',sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.59574547e+05, -9.02193229e-01,  7.59689576e+05,\n",
       "         9.92711672e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_sub).to_excel('test_grid_sub.xlsx')\n",
    "pd.DataFrame(moms_sub).to_excel('test_moms_sub.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_quasi_jacobian(grid_sub, moms_sub, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_msm_identification(\n",
    "        simulate_moments,\n",
    "        res,\n",
    "        moments_cov,\n",
    "        1000,\n",
    "        n_obs = data.shape[0],\n",
    "        weights = 'diagonal',\n",
    "        kernel = 'uniform',\n",
    "        sampling = \"sobol\",\n",
    "        bandwidth = None,\n",
    "        cutoff = None,\n",
    "        population_mc_kwgs = None,\n",
    "        simulate_moments_kwargs= None,\n",
    "        logging = False,\n",
    "        log_options = None,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.ii) Linear approximation\n",
    "## Kernels for step 2.ii)\n",
    "\n",
    "TO DO - solve with scipy.optimize.linprog\n",
    "\n",
    " - uniform\n",
    " - Epanchnikov- to do later\n",
    " - cosine - to do later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('assignment_5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4a299800501f871bbb90ae62193ee27158c182734852d8fba03b7f21f11a1c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
