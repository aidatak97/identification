{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification Task \n",
    "\n",
    "## What we need\n",
    "\n",
    "We need a function called check_ml_identification that it easy to use and performs the identification check described in [this paper](https://arxiv.org/pdf/1907.13093.pdf). The different variants (e.g. different methods of sampling uniformly from likelihood level sets) can be selected via the optional arguments of check_ml_identification.  The output will either be a dictionary (if it is a small set of outputs that every user will want) or a results object similar to the result of estimate_ml (if there are many different test statistics).\n",
    "\n",
    "## Task 1: Planning\n",
    "\n",
    "- Write down which model specific inputs a user has to supply in order to do an identification check. The names should be aligned with estimate_ml where possible. It will definitely be a likelihood function and a result of estimate_ml but there might be more. \n",
    "- Write down which kinds of outputs a user will get, what they mean and how they should be visualized in a paper (plots, tables, ...). \n",
    "- Write docstrings for check_ml_identification before you actually implement it\n",
    "- Adjust our [simple example](https://estimagic.readthedocs.io/en/stable/getting_started/estimation/first_likelihood_estimation_with_estimagic.html) such that it has a second variable that can be arbitrarily correlated with x (i.e. add an identification problem)\n",
    "- Start to write a tutorial in a notebook that shows how the new function will be used and what the outputs mean\n",
    "\n",
    "## Remarks\n",
    "\n",
    "- You can for now assume that the model parameters (params) are a 1d numpy array. We talk about making this more flexible later. \n",
    "- The idea behind writing the documentation first is that it lets you focus completely on a user friendly interface and a high level understanding. Also, we will probably ask for changes after you show us your proposed interface. If you had already implemented it, you would have to change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 1 - interface - inputs and outputs\n",
    "def check_ml_identification():\n",
    "    \"\"\" Do detecting of identification failure in moment condition models. \n",
    "    Performs the identification check as described in Forneron, J. J. (2019).\n",
    "    Introduces the quasi-Jacobian matrix computed as a slope of a linear approximation of the moments\n",
    "    of the estimate of the identified set. It is asymptotically singular when local or global \n",
    "    identification fails and equivalent to theusual Jacobian matrix which has full rank when\n",
    "    model is point and locally identified.\n",
    "\n",
    "    Args\n",
    "        simulate_moments (callable) – Function that takes as inputs model parameters, data and potentially \n",
    "        other keyword arguments and returns a pytree with simulated moments.  If the function returns a dict containing \n",
    "        the key \"simulated_moments\" we only use the value corresponding to that key. Other entries are stored in \n",
    "        the log database if you use logging.\n",
    "        simulate_moments_kwargs (dict) – Additional keyword arguments for simulate_moments with necessarily included\n",
    "        data on dependent and independent variables from the model specification.\n",
    "        objective (callable) - the GMM objective function. By default, based on L2 norm.\n",
    "        weights (str) – One of “diagonal” (default), “identity” or “optimal”.  Note that “optimal” refers to \n",
    "        the asymptotically optimal weighting matrix and is often not a good choice due to large finite sample bias.\n",
    "        bandwidth (float) - By default is calculated in the form of sqrt(2log(log[n])/n). Required for the calculation\n",
    "        of quasi-jacobian matrix.\n",
    "        kernel (callable) - By default  is the uniform kernel K(U) which is indicator function for |U|<=1. Required \n",
    "        for the calculation of quasi-jacobian matrix.\n",
    "        cutoff (float) - By default is calculated in the form sqrt(2log[n]/n). Required for identification category selection.\n",
    "        draws (float)  - The number of draws for sampling on level sets. Supposed to be sufficiently large.\n",
    "        sampling (str) - Methods of sampling uniformly from likelihood level sets. One of the available options for \n",
    "        direct approach using \"sobol\" or \"halton\" sequence or adaptive sampling by \"population_mc\".\n",
    "        significance - The significance level with default level 5%.\n",
    "        H0 (dict) - Required for subvector inference. For example, b10 = 0.\n",
    "        reparametrization - .\n",
    "        logging (pathlib.Path, str or False) – Path to sqlite3 file (which typically has the file extension .db. \n",
    "        If the file does not exist, it will be created. The dashboard can only be used when logging is used.\n",
    "        log_options (dict) – Additional keyword arguments to configure the logging.\n",
    "\n",
    "    Returns\n",
    "        dict: The estimated quasi-Jacobian, singular values, identification category, subvestor inference \n",
    "        test output and confidence set.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimate_ml\n",
    "https://estimagic.readthedocs.io/en/stable/reference_guides/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16cdb2918d68fc038b94e1d120e3768c77cd4fa604719a926758a56fae290753"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
